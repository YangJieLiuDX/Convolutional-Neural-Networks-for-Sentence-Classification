# Convolutional-Neural-Networks-for-Sentence-Classification
In this project, we attempt to reproduce and improve the results achieved by Yoon Kim (2014), in [1] with no published code. We implement the proposed models in his paper, which describes sentence classifiers using CNN on top of pre-trained word vectors, Word2Vec. Classification in [1], is performed on multiple datasets, with static and minimally fine-tuned Word2Vec, feeding a single layer CNN. To improve the state-of-the-art, both static and fine-tuned word vectors are used in 2 separate channels to classify sentences[1]. In this work, we simplify Kimâ€™s approach and instead focus only on the use of different kernel sizes with parallel layers. We see that the skill of the model on the unseen test dataset was very impressive, achieving 89%, which is above the skill of the model reported in the 2014 paper. We observed, fine-tuning the pre-trained vectors for specific task improves accuracy over static vectors, and we were able to reach accuracy mentioned in [1] for MR dataset.
