{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Mini_project_4.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "-_cBwiR3MCgp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Yk2OyTKYfZ4k",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd  \n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "plt.style.use('fivethirtyeight')\n",
        "%matplotlib inline\n",
        "%config InlineBackend.figure_format = 'retina'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OthHJM3YfdVz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "clean_mr_texts = pd.read_csv('drive/My Drive/ML_miniproject_4/MR(2000).csv')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2LVQLXuINBFc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "clean_mr_texts[clean_mr_texts.target == 1].head(10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_7VWC6sRNr8a",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "clean_mr_texts.target.value_counts()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zJtbL4wTj7yP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "clean_mr_texts.dropna(inplace=True)\n",
        "clean_mr_texts.reset_index(drop=True,inplace=True)\n",
        "clean_mr_texts.info()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1ymROoPEkABM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x = clean_mr_texts.text\n",
        "y = clean_mr_texts.target"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "eg_lUFBvkeUs",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "SEED = 2000\n",
        "x_train, x_validation_and_test, y_train, y_validation_and_test = train_test_split(x, y, test_size=.02, random_state=SEED)\n",
        "x_validation, x_test, y_validation, y_test = train_test_split(x_validation_and_test, y_validation_and_test, test_size=.5, random_state=SEED)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rKAnmgZwnMah",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print (\"Train set has total {0} entries with {1:.2f}% negative, {2:.2f}% positive\".format(len(x_train),\n",
        "                                                                             (len(x_train[y_train == 0]) / (len(x_train)*1.))*100,\n",
        "                                                                            (len(x_train[y_train == 1]) / (len(x_train)*1.))*100))\n",
        "print (\"Validation set has total {0} entries with {1:.2f}% negative, {2:.2f}% positive\".format(len(x_validation),\n",
        "                                                                             (len(x_validation[y_validation == 0]) / (len(x_validation)*1.))*100,\n",
        "                                                                            (len(x_validation[y_validation == 1]) / (len(x_validation)*1.))*100))\n",
        "print (\"Test set has total {0} entries with {1:.2f}% negative, {2:.2f}% positive\".format(len(x_test),\n",
        "                                                                             (len(x_test[y_test == 0]) / (len(x_test)*1.))*100,\n",
        "                                                                            (len(x_test[y_test == 1]) / (len(x_test)*1.))*100))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "G_ZW6325vkuk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "tqdm.pandas(desc=\"progress-bar\")\n",
        "import gensim\n",
        "from gensim.models.word2vec import Word2Vec\n",
        "from gensim.models.doc2vec import TaggedDocument\n",
        "import multiprocessing\n",
        "from sklearn import utils"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "T2sR0BkGv39d",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def labelize_ug(comments,label):\n",
        "    result = []\n",
        "    prefix = label\n",
        "    for i, t in zip(comments.index, comments):\n",
        "        result.append(TaggedDocument(t.split(), [prefix + '_%s' % i]))\n",
        "    return result"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "s3BuyZs7vuMJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "all_x = pd.concat([x_train,x_validation,x_test])\n",
        "all_x_w2v = labelize_ug(all_x, 'all')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hw1eoU8Bv9MY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "cores = multiprocessing.cpu_count()\n",
        "model_ug_cbow = Word2Vec(sg=0, size=100, negative=5, window=2, min_count=2, workers=cores, alpha=0.065, min_alpha=0.065)\n",
        "model_ug_cbow.build_vocab([x.words for x in tqdm(all_x_w2v)])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4hQ3KxpiwB88",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%%time\n",
        "for epoch in range(20):\n",
        "    model_ug_cbow.train(utils.shuffle([x.words for x in tqdm(all_x_w2v)]), total_examples=len(all_x_w2v), epochs=1)\n",
        "    model_ug_cbow.alpha -= 0.002\n",
        "    model_ug_cbow.min_alpha = model_ug_cbow.alpha"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "x8cgy9vmwHvc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model_ug_sg = Word2Vec(sg=1, size=100, negative=5, window=2, min_count=2, workers=cores, alpha=0.065, min_alpha=0.065)\n",
        "model_ug_sg.build_vocab([x.words for x in tqdm(all_x_w2v)])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Fz6ncnEOwNk0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%%time\n",
        "for epoch in range(20):\n",
        "    model_ug_sg.train(utils.shuffle([x.words for x in tqdm(all_x_w2v)]), total_examples=len(all_x_w2v), epochs=1)\n",
        "    model_ug_sg.alpha -= 0.002\n",
        "    model_ug_sg.min_alpha = model_ug_sg.alpha"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KFn8IRaJwUbC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model_ug_cbow.save('drive/My Drive/ML_miniproject_4/w2v_model_ug_cbow.word2vec')\n",
        "model_ug_sg.save('drive/My Drive/ML_miniproject_4/w2v_model_ug_sg.word2vec')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LW658G6mw0C4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from gensim.models import KeyedVectors\n",
        "model_ug_cbow = KeyedVectors.load('drive/My Drive/ML_miniproject_4/w2v_model_ug_cbow.word2vec')\n",
        "model_ug_sg = KeyedVectors.load('drive/My Drive/ML_miniproject_4/w2v_model_ug_sg.word2vec')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TiAox_Ukw3Uq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a428c013-ce00-4f76-9bf3-846ad0c1b334"
      },
      "cell_type": "code",
      "source": [
        "len(model_ug_cbow.wv.vocab.keys())"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "27139"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "metadata": {
        "id": "-ptnrdoYw8lz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6711a6d2-79e7-4f1e-dc0d-77d33baa95a5"
      },
      "cell_type": "code",
      "source": [
        "embeddings_index = {}\n",
        "for w in model_ug_cbow.wv.vocab.keys():\n",
        "    embeddings_index[w] = np.append(model_ug_cbow.wv[w],model_ug_sg.wv[w])\n",
        "print('Found %s word vectors.' % len(embeddings_index))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 27139 word vectors.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "WQrJ0lvGxAp8",
        "colab_type": "code",
        "outputId": "61f4bdf4-adcc-4f53-d5e0-d874c6124e60",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "tokenizer = Tokenizer(num_words=100000)\n",
        "tokenizer.fit_on_texts(x_train)\n",
        "sequences = tokenizer.texts_to_sequences(x_train)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "XghZhJZXxGBW",
        "colab_type": "code",
        "outputId": "668e16bd-c8a2-49c4-829e-ce6924565827",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "len(tokenizer.word_index)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "46062"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "metadata": {
        "id": "fieeZKqMxJ7k",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "for x in x_train[:5]:\n",
        "    print (x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uSpwdIXzxRf5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "sequences[:5]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZW53AC46xZcE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "length = []\n",
        "for x in x_train:\n",
        "    length.append(len(x.split()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "E2GVYa3Gxc75",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "40360d9b-a979-4a8a-b436-06cc36c49b44"
      },
      "cell_type": "code",
      "source": [
        "max(length)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1380"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "metadata": {
        "id": "hbInqVVRxiBs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ab38d355-e974-4cf8-b9cd-42e1bb7c06f4"
      },
      "cell_type": "code",
      "source": [
        "x_train_seq = pad_sequences(sequences, maxlen=1380)\n",
        "print('Shape of data tensor:', x_train_seq.shape)"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of data tensor: (1960, 1380)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "a8ek8FRrxlzl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x_train_seq[:5]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HZDVMEjNxpUn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "sequences_val = tokenizer.texts_to_sequences(x_validation)\n",
        "x_val_seq = pad_sequences(sequences_val, maxlen=1380)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7c-GlglExszQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "num_words = 100000\n",
        "embedding_matrix = np.zeros((num_words, 200))\n",
        "for word, i in tokenizer.word_index.items():\n",
        "    if i >= num_words:\n",
        "        continue\n",
        "    embedding_vector = embeddings_index.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        embedding_matrix[i] = embedding_vector"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_0NGHJjfxv-l",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "np.array_equal(embedding_matrix[5] ,embeddings_index.get('my'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9noGONmGyNCX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "seed = 7\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout\n",
        "from keras.layers import Flatten\n",
        "from keras.layers.embeddings import Embedding\n",
        "from keras.utils.vis_utils import plot_model\n",
        "from keras.layers import Conv1D, GlobalMaxPooling1D"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "35DLT1uByRQv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model_ptw2v = Sequential()\n",
        "e = Embedding(100000, 200, weights=[embedding_matrix], input_length=1380, trainable=False)\n",
        "model_ptw2v.add(e)\n",
        "model_ptw2v.add(Flatten())\n",
        "model_ptw2v.add(Dense(256, activation='relu'))\n",
        "model_ptw2v.add(Dense(1, activation='sigmoid'))\n",
        "model_ptw2v.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model_ptw2v.fit(x_train_seq, y_train, validation_data=(x_val_seq, y_validation), epochs=5, batch_size=32, verbose=2)\n",
        "print(model_ptw2v.summary())\n",
        "plot_model(model_ptw2v, show_shapes=True, to_file='ptw2v_1.png')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "H0c5DGmlyb6L",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.utils.vis_utils import plot_model\n",
        "model_ptw2v = Sequential()\n",
        "e = Embedding(100000, 200, input_length=1380)\n",
        "model_ptw2v.add(e)\n",
        "model_ptw2v.add(Flatten())\n",
        "model_ptw2v.add(Dense(256, activation='relu'))\n",
        "model_ptw2v.add(Dense(1, activation='sigmoid'))\n",
        "model_ptw2v.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model_ptw2v.fit(x_train_seq, y_train, validation_data=(x_val_seq, y_validation), epochs=5, batch_size=32, verbose=2)\n",
        "print(model_ptw2v.summary())\n",
        "plot_model(model_ptw2v, show_shapes=True, to_file='ptw2v_2.png')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lMsv9H8zykLP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model_ptw2v = Sequential()\n",
        "e = Embedding(100000, 200, weights=[embedding_matrix], input_length=1380, trainable=True)\n",
        "model_ptw2v.add(e)\n",
        "model_ptw2v.add(Flatten())\n",
        "model_ptw2v.add(Dense(256, activation='relu'))\n",
        "model_ptw2v.add(Dense(1, activation='sigmoid'))\n",
        "model_ptw2v.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model_ptw2v.fit(x_train_seq, y_train, validation_data=(x_val_seq, y_validation), epochs=5, batch_size=32, verbose=2)\n",
        "print(model_ptw2v.summary())\n",
        "plot_model(model_ptw2v, show_shapes=True, to_file='ptw2v_3.png')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cbCf6Q0wyw8d",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## **Convolutional Neural Network**"
      ]
    },
    {
      "metadata": {
        "id": "P_3CUX4yyx-y",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.layers import Conv1D, GlobalMaxPooling1D"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tq83h1XHy3_o",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "structure_test = Sequential()\n",
        "e = Embedding(100000, 200, input_length=1380)\n",
        "structure_test.add(e)\n",
        "structure_test.add(Conv1D(filters=100, kernel_size=2, padding='valid', activation='relu', strides=1))\n",
        "structure_test.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PyWJmgNQy_iU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "structure_test = Sequential()\n",
        "e = Embedding(100000, 200, input_length=1380)\n",
        "structure_test.add(e)\n",
        "structure_test.add(Conv1D(filters=100, kernel_size=2, padding='valid', activation='relu', strides=1))\n",
        "structure_test.add(GlobalMaxPooling1D())\n",
        "structure_test.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VdC1EI2xzDN5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model_cnn_01 = Sequential()\n",
        "e = Embedding(100000, 200, weights=[embedding_matrix], input_length=1380, trainable=False)\n",
        "model_cnn_01.add(e)\n",
        "model_cnn_01.add(Conv1D(filters=100, kernel_size=2, padding='valid', activation='relu', strides=1))\n",
        "model_cnn_01.add(GlobalMaxPooling1D())\n",
        "model_cnn_01.add(Dense(256, activation='relu'))\n",
        "model_cnn_01.add(Dense(1, activation='sigmoid'))\n",
        "model_cnn_01.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model_cnn_01.fit(x_train_seq, y_train, validation_data=(x_val_seq, y_validation), epochs=5, batch_size=32, verbose=2)\n",
        "print(model_cnn_01.summary())\n",
        "plot_model(model_cnn_01, show_shapes=True, to_file='model_cnn_01.png')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "A4MW3GHhzHrW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model_cnn_02 = Sequential()\n",
        "e = Embedding(100000, 200, input_length=1380)\n",
        "model_cnn_02.add(e)\n",
        "model_cnn_02.add(Conv1D(filters=100, kernel_size=2, padding='valid', activation='relu', strides=1))\n",
        "model_cnn_02.add(GlobalMaxPooling1D())\n",
        "model_cnn_02.add(Dense(256, activation='relu'))\n",
        "model_cnn_02.add(Dense(1, activation='sigmoid'))\n",
        "model_cnn_02.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model_cnn_02.fit(x_train_seq, y_train, validation_data=(x_val_seq, y_validation), epochs=5, batch_size=32, verbose=2)\n",
        "print(model_cnn_02.summary())\n",
        "plot_model(model_cnn_02, show_shapes=True, to_file='model_cnn_02.png')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pXbVVEcpzN83",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model_cnn_03 = Sequential()\n",
        "e = Embedding(100000, 200, weights=[embedding_matrix], input_length=1380, trainable=True)\n",
        "model_cnn_03.add(e)\n",
        "model_cnn_03.add(Conv1D(filters=100, kernel_size=2, padding='valid', activation='relu', strides=1))\n",
        "model_cnn_03.add(GlobalMaxPooling1D())\n",
        "model_cnn_03.add(Dense(256, activation='relu'))\n",
        "model_cnn_03.add(Dense(1, activation='sigmoid'))\n",
        "model_cnn_03.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model_cnn_03.fit(x_train_seq, y_train, validation_data=(x_val_seq, y_validation), epochs=5, batch_size=32, verbose=2)\n",
        "print(model_cnn_03.summary())\n",
        "plot_model(model_cnn_03, show_shapes=True, to_file='model_cnn_03.png')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GcvtYayKzTIw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.layers import Input, Dense, concatenate, Activation\n",
        "from keras.models import Model\n",
        "from keras.utils.vis_utils import plot_model\n",
        "\n",
        "MR_input = Input(shape=(1380,), dtype='int32')\n",
        "\n",
        "tweet_encoder = Embedding(100000, 200, weights=[embedding_matrix], input_length=1380, trainable=True)(MR_input)\n",
        "bigram_branch = Conv1D(filters=100, kernel_size=3, padding='valid', activation='relu', strides=1)(tweet_encoder)\n",
        "bigram_branch = GlobalMaxPooling1D()(bigram_branch)\n",
        "trigram_branch = Conv1D(filters=100, kernel_size=4, padding='valid', activation='relu', strides=1)(tweet_encoder)\n",
        "trigram_branch = GlobalMaxPooling1D()(trigram_branch)\n",
        "fourgram_branch = Conv1D(filters=100, kernel_size=5, padding='valid', activation='relu', strides=1)(tweet_encoder)\n",
        "fourgram_branch = GlobalMaxPooling1D()(fourgram_branch)\n",
        "merged = concatenate([bigram_branch, trigram_branch, fourgram_branch], axis=1)\n",
        "\n",
        "merged = Dense(256, activation='relu')(merged)\n",
        "merged = Dropout(0.5)(merged)\n",
        "merged = Dense(1)(merged)\n",
        "output = Activation('sigmoid')(merged)\n",
        "model = Model(inputs=[MR_input], outputs=[output])\n",
        "model.compile(loss='binary_crossentropy',\n",
        "                  optimizer='adam',\n",
        "                  metrics=['accuracy'])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "f3qSmQAgzXKl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.callbacks import ModelCheckpoint\n",
        "\n",
        "filepath=\"CNN_best_weights.{epoch:02d}-{val_acc:.4f}.hdf5\"\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
        "\n",
        "model.fit(x_train_seq, y_train, batch_size=50, epochs=5,\n",
        "                     validation_data=(x_val_seq, y_validation), callbacks = [checkpoint])\n",
        "model.summary()\n",
        "plot_model(model, show_shapes=True, to_file='model_final.png')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_ulxiQnZzdX8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.models import load_model\n",
        "loaded_CNN_model = load_model('CNN_best_weights.04-0.7000.hdf5')\n",
        "loaded_CNN_model.evaluate(x=x_val_seq, y=y_validation)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BZWzE9VnztFw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Final Model Evaluation with Test Set"
      ]
    },
    {
      "metadata": {
        "id": "aM6i038V0hJX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "sequences_test = tokenizer.texts_to_sequences(x_test)\n",
        "x_test_seq = pad_sequences(sequences_test, maxlen=1380)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OPOwLKje0qib",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "loaded_CNN_model.evaluate(x=x_test_seq, y=y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}